{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "from nltk.probability import FreqDist, LidstoneProbDist\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "from autocorrect import Speller\n",
    "\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample data loading from a text file and remove line number\n",
    "with open('./eng_news_2020_10K-sentences-1.txt', 'r', encoding='utf-8') as file:\n",
    "    data = file.readlines()\n",
    "\n",
    "processed_data = []\n",
    "\n",
    "for line in data:\n",
    "    sentances = sent_tokenize(line)\n",
    "    for sentence in sentances:\n",
    "        words = sentence.split()[1:]\n",
    "        sentence = ' '.join(words)\n",
    "        processed_data.append(sentence)\n",
    "\n",
    "print(processed_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Model:\n",
    "    def __init__(self, ngram:int, th:int = 0.060, seed:int = 42) -> None:\n",
    "        self.model          =   {}\n",
    "        self.n              =   ngram\n",
    "        self.spell          =   Speller(lang='en')\n",
    "        self.stop_words     =   set(stopwords.words('english'))\n",
    "        self.max_next       =   100\n",
    "        self.dictionary     =   {}\n",
    "        self.thresold       =   th\n",
    "        self.seeds          =   seed\n",
    "        self.random         =   random\n",
    "        self.start_tag      =   '<s>'\n",
    "        self.stop_tag       =   '</s>'\n",
    "\n",
    "        self.random.seed(self.seeds)\n",
    "\n",
    "    def nextWord(self, context:str, random:bool = True)->str:\n",
    "        context = self.getTokens(context)[:-1]\n",
    "        return self._nextWord(tokens=context,random=random)\n",
    "    \n",
    "    def _nextWord(self, tokens:list, random=True)->str:\n",
    "        words = self._getTopWords(tokens)\n",
    "        if len(words) > 1 and random:\n",
    "            return self.random.choice(words)\n",
    "        elif len(words) > 0:\n",
    "            return words[0]\n",
    "        else:\n",
    "            return self.stop_tag\n",
    "        \n",
    "    def _getTopWords(self,tokens:list, n:int= None)->list:\n",
    "        req = self.n-1\n",
    "        if len(tokens) > req:\n",
    "            tokens = tokens[-req:]\n",
    "        try:\n",
    "            next_words = sorted(self.model[tuple(tokens)].items(), key= lambda x: x[1], reverse=True)\n",
    "            words = [word[0] for word in next_words if word[1] > self.thresold]\n",
    "            if n is not None:\n",
    "                return words[:n]\n",
    "            return words\n",
    "        except:\n",
    "            return [self.stop_tag]\n",
    "        \n",
    "    def getTokens(self, sentence:str)->list:\n",
    "        tokens = []\n",
    "        token_list = list(word_tokenize(sentence.lower()))\n",
    "        token_list = [word for word in token_list if word.isalnum()]\n",
    "        token_list = list(filter(lambda token: nltk.tokenize.punkt.PunktToken(token).is_non_punct, token_list))\n",
    "        prefix = [self.start_tag]*(self.n-1)\n",
    "        sufix = [self.stop_tag]\n",
    "        tokens.extend(prefix)\n",
    "        tokens.extend(token_list)\n",
    "        tokens.extend(sufix)\n",
    "        return tokens\n",
    "    \n",
    "    def addToDictionary(self, word:str):\n",
    "        entry = self.dictionary.get(word)\n",
    "        if entry is None:\n",
    "            self.dictionary[word] = 0\n",
    "        self.dictionary[word] += 1\n",
    "        \n",
    "    def fit(self, train_data:list):\n",
    "        for sentence in train_data:\n",
    "            words = self.getTokens(sentence)\n",
    "            n_grams_list = list(ngrams(words, self.n))\n",
    "            for n_grams in n_grams_list:\n",
    "                key, value = n_grams[:-1], n_grams[-1]\n",
    "                if key not in self.model:\n",
    "                    self.model[key] = {}\n",
    "                if value not in self.model[key]:\n",
    "                    self.model[key][value] = 1\n",
    "                else:\n",
    "                    self.model[key][value] += 1\n",
    "\n",
    "        for key in self.model:\n",
    "            total_count = float(sum(self.model[key].values()))\n",
    "            for w3 in self.model[key]:\n",
    "                self.model[key][w3] /= total_count\n",
    "\n",
    "    def complete_sentence(self, context:str, random:bool = True)->str:\n",
    "        words = self.getTokens(context)[:-1]\n",
    "        next_word = words[-1]\n",
    "        max = self.max_next\n",
    "        while  next_word !=  self.stop_tag:\n",
    "            next_word = self._nextWord(words,random)\n",
    "            words.append(next_word)\n",
    "            max -= 1\n",
    "            if max==0:\n",
    "                break\n",
    "        sentence = \" \".join(words)\n",
    "        sentence = sentence.replace(self.start_tag, \"\")\n",
    "        sentence = sentence.replace(self.stop_tag, \".\")\n",
    "        sentence = sentence.strip()\n",
    "        return sentence\n",
    "\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(3)\n",
    "model.fit(processed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s defence lawyer disagrees saying he believes his team s injury is but he s not a member of sdp one of the .\n",
      "s younger sister ousa who performed at a time when scotland s contribution to trump victory in itself and many still go back and seeking to trade 1 billion including a throat snare an oil slick hit the right thing with the .\n",
      "s ambassador to britain one of those who were most at risk for complications from and fund research in children mental health care .\n",
      "s defence lawyer disagrees saying he believes his team had to be a .\n",
      "s defence lawyer disagrees saying he believes getting young people living around etosha should be a .\n"
     ]
    }
   ],
   "source": [
    "#With Random\n",
    "trial = 1\n",
    "while trial <=5:\n",
    "    print(model.complete_sentence(\"<s>\"))\n",
    "    trial+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s defence lawyer disagrees saying he believes his client had not been a lot of people who are .\n",
      "s defence lawyer disagrees saying he believes his client had not been a lot of people who are .\n",
      "s defence lawyer disagrees saying he believes his client had not been a lot of people who are .\n",
      "s defence lawyer disagrees saying he believes his client had not been a lot of people who are .\n",
      "s defence lawyer disagrees saying he believes his client had not been a lot of people who are .\n"
     ]
    }
   ],
   "source": [
    "#With Random\n",
    "trial = 1\n",
    "while trial <=5:\n",
    "    print(model.complete_sentence(\"<s>\",random=False))\n",
    "    trial+=1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
